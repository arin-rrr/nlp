{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка датасетов"
      ],
      "metadata": {
        "id": "yWBfQ5lGHJ_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ylpXsqdHJeZ"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "jGuvH7lVHg4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_news = datasets.load_dataset(\"ag_news\")"
      ],
      "metadata": {
        "id": "-qSyCvbwIlkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_imdb = datasets.load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "aLlXwtNhI2ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Тексты и метки - news**"
      ],
      "metadata": {
        "id": "mHYEZBrUKYG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "count0, count1, count2, count3 = 0, 0, 0, 0\n",
        "dataset_short_news = []\n",
        "for i in range(len(dataset_news['train'])):\n",
        "  if dataset_news['train'][i]['label'] == 0 and count0 < 2000:\n",
        "    dataset_short_news.append({'news': dataset_news['train'][i]['text'], 'label': 0})\n",
        "    count0 += 1\n",
        "  elif dataset_news['train'][i]['label'] == 1 and count1 < 2000:\n",
        "    dataset_short_news.append({'news': dataset_news['train'][i]['text'], 'label': 1})\n",
        "    count1 += 1\n",
        "  elif dataset_news['train'][i]['label'] == 2 and count2 < 2000:\n",
        "    dataset_short_news.append({'news': dataset_news['train'][i]['text'], 'label': 2})\n",
        "    count2 += 1\n",
        "  elif dataset_news['train'][i]['label'] == 3 and count3 < 2000:\n",
        "    dataset_short_news.append({'news': dataset_news['train'][i]['text'], 'label': 3})\n",
        "    count3 += 1\n",
        "\n",
        "random.shuffle(dataset_short_news)\n",
        "dataset_news = {'train': dataset_short_news[:6400], 'test': dataset_short_news[6400:]}"
      ],
      "metadata": {
        "id": "y98cnoUQI7rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_X = []\n",
        "for i in range(len(dataset_news['train'])):\n",
        "  news_X.append(dataset_news['train'][i]['news'])\n",
        "for i in range(len(dataset_news['test'])):\n",
        "  news_X.append(dataset_news['test'][i]['news'])"
      ],
      "metadata": {
        "id": "lfW1JfiRJw44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_y = []\n",
        "for i in range(len(dataset_news['train'])):\n",
        "  news_y.append(dataset_news['train'][i]['label'])\n",
        "for i in range(len(dataset_news['test'])):\n",
        "  news_y.append(dataset_news['test'][i]['label'])"
      ],
      "metadata": {
        "id": "aEUfX4kNKFn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Тексты и метки - imdb**"
      ],
      "metadata": {
        "id": "DTg51ACjKc9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count0, count1 = 0, 0\n",
        "dataset_short_imdb = []\n",
        "\n",
        "for i in range(len(dataset_imdb['train'])):\n",
        "  if dataset_imdb['train'][i]['label'] == 0 and count0 < 4000:\n",
        "    dataset_short_imdb.append({'text': dataset_imdb['train'][i]['text'], 'label': 0})\n",
        "    count0 += 1\n",
        "  elif dataset_imdb['train'][i]['label'] == 1 and count1 < 4000:\n",
        "    dataset_short_imdb.append({'text': dataset_imdb['train'][i]['text'], 'label': 1})\n",
        "    count1 += 1\n",
        "\n",
        "random.shuffle(dataset_short_imdb)\n",
        "dataset_imdb = {'train': dataset_short_imdb[:6400], 'test': dataset_short_imdb[6400:]}"
      ],
      "metadata": {
        "id": "jMqNrP1wKfy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_X = []\n",
        "for i in range(len(dataset_imdb['train'])):\n",
        "  imdb_X.append(dataset_imdb['train'][i]['text'])\n",
        "for i in range(len(dataset_imdb['test'])):\n",
        "  imdb_X.append(dataset_imdb['test'][i]['text'])"
      ],
      "metadata": {
        "id": "3I9Kkgu6K_bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_y = []\n",
        "for i in range(len(dataset_imdb['train'])):\n",
        "  imdb_y.append(dataset_imdb['train'][i]['label'])\n",
        "for i in range(len(dataset_imdb['test'])):\n",
        "  imdb_y.append(dataset_imdb['test'][i]['label'])"
      ],
      "metadata": {
        "id": "EFIwU3YOLK0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Обучаем и тестируем LSTM"
      ],
      "metadata": {
        "id": "AAOMZ7a5LyAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras"
      ],
      "metadata": {
        "id": "k65ZEcZmMCyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "YwIeY8WpL6wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "qSQfaieqMSBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Токенезируем тексты и подготавливаем метки - news**"
      ],
      "metadata": {
        "id": "vrFWba1rMjLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()"
      ],
      "metadata": {
        "id": "Hetil1GdM-0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts(news_X)  # создаём словарь слово - индекс"
      ],
      "metadata": {
        "id": "aoDuyl0vNEZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_news = token.texts_to_sequences(news_X)  # предложение в последовательность чисел\n",
        "X_news = pad_sequences(X_news, maxlen=50)  # выравнивание по длине"
      ],
      "metadata": {
        "id": "7H5ZVQ2VNTwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_news = label_encoder.fit_transform(news_y)\n",
        "y_news = np.array(y_news)"
      ],
      "metadata": {
        "id": "DfTSLgjDNtAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Токенезируем тексты и подготавливаем метки - imdb**"
      ],
      "metadata": {
        "id": "uKxIgopaOAsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_imdb = Tokenizer()"
      ],
      "metadata": {
        "id": "kqLoXyxUOGUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_imdb.fit_on_texts(imdb_X)"
      ],
      "metadata": {
        "id": "fER2HdsaOpm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_imdb = token_imdb.texts_to_sequences(imdb_X)\n",
        "X_imdb = pad_sequences(X_imdb, maxlen=200)"
      ],
      "metadata": {
        "id": "0DP6OrOuOvdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder_imdb = LabelEncoder()\n",
        "y_imdb = label_encoder_imdb.fit_transform(imdb_y)\n",
        "y_imdb = np.array(y_imdb)"
      ],
      "metadata": {
        "id": "a3bYy1IBO-Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Делим на train/test**"
      ],
      "metadata": {
        "id": "etZhUMtCPQdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_news, X_test_news, y_train_news, y_test_news = train_test_split(X_news, y_news, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Pa9CkSBZPVWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = train_test_split(X_imdb, y_imdb, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "4kA5t2OAPqLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM для news**"
      ],
      "metadata": {
        "id": "M6uMllyTPu03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_news = Sequential([\n",
        "    Embedding(input_dim=len(token.word_index) + 1, output_dim=100, input_shape=(50,)),\n",
        "    SpatialDropout1D(0.2),\n",
        "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "BH45U0mGP_8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_news.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QHDOLiTnQX-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_news.summary()"
      ],
      "metadata": {
        "id": "6rF12FirQerh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обучение модели**"
      ],
      "metadata": {
        "id": "Sbvi4MVfRSnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_news = model_news.fit(X_train_news, y_train_news, validation_split=0.1, epochs=8, batch_size=64)"
      ],
      "metadata": {
        "id": "EYOEhlBbRV5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_news = model_news.predict(X_test_news)\n",
        "y_pred_news = (y_pred_news > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "APPsjG84Rinh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_classes = np.argmax(y_pred_news, axis=1)"
      ],
      "metadata": {
        "id": "btA0GjfYS1Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_news, y_pred_classes))"
      ],
      "metadata": {
        "id": "lsAyIUOERpn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM для imdb**"
      ],
      "metadata": {
        "id": "5obBObDxVB14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_imdb = Sequential([\n",
        "    Embedding(input_dim=len(token_imdb.word_index) + 1, output_dim=100, input_shape=(100,)),\n",
        "    SpatialDropout1D(0.2),\n",
        "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "fAbK12EDVQCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_imdb.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "j1RXkE0KVvCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_imdb.summary()"
      ],
      "metadata": {
        "id": "Qy63IX2dWZ0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_imdb = model_imdb.fit(X_train_imdb, y_train_imdb, validation_split=0.1, epochs=8, batch_size=64)"
      ],
      "metadata": {
        "id": "jnBc0HtHWdo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_imdb = model_imdb.predict(X_test_imdb)\n",
        "y_pred_imdb = (y_pred_imdb > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "3qaygmlxWkQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_classes_imdb = np.argmax(y_pred_imdb, axis=1)"
      ],
      "metadata": {
        "id": "edBvt0srW0Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_imdb, y_pred_classes_imdb))"
      ],
      "metadata": {
        "id": "e7_49BsvW7NC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}