{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNTud0uX38w-"
      },
      "source": [
        "# 1. Берём 2 датасета\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr5TPvwC3x-g",
        "outputId": "984f33e6-0141-488f-a535-eca5f4870778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 120000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 7600\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загружаем датасет 'ag_news' (определяем сообщение - спам/не спам)\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jegDQ29CNj2i"
      },
      "outputs": [],
      "source": [
        "# всего 4 класса, по 25% каждого в dataset['train']\n",
        "# сформирую датасет из 8000 примеров, по 2000 примеров на каждый класс\n",
        "\n",
        "count0, count1, count2, count3 = 0, 0, 0, 0\n",
        "dataset_short = []\n",
        "for i in range(len(dataset['train'])):\n",
        "  if dataset['train'][i]['label'] == 0 and count0 < 2000:\n",
        "    dataset_short.append({'news': dataset['train'][i]['text'], 'label': 0})\n",
        "    count0 += 1\n",
        "  elif dataset['train'][i]['label'] == 1 and count1 < 2000:\n",
        "    dataset_short.append({'news': dataset['train'][i]['text'], 'label': 1})\n",
        "    count1 += 1\n",
        "  elif dataset['train'][i]['label'] == 2 and count2 < 2000:\n",
        "    dataset_short.append({'news': dataset['train'][i]['text'], 'label': 2})\n",
        "    count2 += 1\n",
        "  elif dataset['train'][i]['label'] == 3 and count3 < 2000:\n",
        "    dataset_short.append({'news': dataset['train'][i]['text'], 'label': 3})\n",
        "    count3 += 1\n",
        "len(dataset_short)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH9SJDcvQ0al"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(dataset_short)\n",
        "dataset = {'train': dataset_short[:6400], 'test': dataset_short[6400:]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__fqnwso4qCY"
      },
      "outputs": [],
      "source": [
        "# Выводим объём выборок\n",
        "print('Объём train:', len(dataset['train']))\n",
        "print('Объём test:', len(dataset['test']))\n",
        "\n",
        "train_texts_news = [s['news'] for s in dataset['train']]\n",
        "test_texts_news = [s['news'] for s in dataset['test']]\n",
        "\n",
        "train_labels_news = [s['label'] for s in dataset['train']]\n",
        "test_labels_news = [s['label'] for s in dataset['test']]\n",
        "\n",
        "# ВЫводим примеры\n",
        "print(train_texts_news[0], train_labels_news[0])\n",
        "print(test_texts_news[0], test_labels_news[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVp4dxk15DPP"
      },
      "outputs": [],
      "source": [
        "dataset_imdb = load_dataset(\"imdb\")\n",
        "\n",
        "count0, count1 = 0, 0\n",
        "dataset_short_imdb = []\n",
        "\n",
        "for i in range(len(dataset_imdb['train'])):\n",
        "  if dataset_imdb['train'][i]['label'] == 0 and count0 < 4000:\n",
        "    dataset_short_imdb.append({'text': dataset_imdb['train'][i]['text'], 'label': 0})\n",
        "    count0 += 1\n",
        "  elif dataset_imdb['train'][i]['label'] == 1 and count1 < 4000:\n",
        "    dataset_short_imdb.append({'text': dataset_imdb['train'][i]['text'], 'label': 1})\n",
        "    count1 += 1\n",
        "len(dataset_short_imdb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv4gtfvYUt_Z"
      },
      "outputs": [],
      "source": [
        "random.shuffle(dataset_short_imdb)\n",
        "dataset_imdb = {'train': dataset_short_imdb[:6400], 'test': dataset_short_imdb[6400:]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EVYVI_BVCmA"
      },
      "outputs": [],
      "source": [
        "# Выводим объём выборок\n",
        "print('Объём train:', len(dataset_imdb['train']))\n",
        "print('Объём test:', len(dataset_imdb['test']))\n",
        "\n",
        "train_texts_imdb = [s['text'] for s in dataset_imdb['train']]\n",
        "test_texts_imdb = [s['text'] for s in dataset_imdb['test']]\n",
        "\n",
        "train_labels_imdb = [s['label'] for s in dataset_imdb['train']]\n",
        "test_labels_imdb = [s['label'] for s in dataset_imdb['test']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLtwj8Pg6Tlb"
      },
      "outputs": [],
      "source": [
        "print(train_texts_imdb[0])\n",
        "print(train_labels_imdb[0])\n",
        "print()\n",
        "print(test_texts_imdb[0])\n",
        "print(test_labels_imdb[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucfq-VUp806M"
      },
      "source": [
        "# 2. Прописываем функции предобработки текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkAWFtn493Gi"
      },
      "outputs": [],
      "source": [
        "# news example\n",
        "news_example = train_texts_news[0]\n",
        "print(news_example)\n",
        "\n",
        "# imdb example\n",
        "imdb_example = train_texts_imdb[0]\n",
        "print(imdb_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ8ugHbM9Kkg"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(set(stopwords.words(\"english\")))\n",
        "\n",
        "def stopwords_special(text):\n",
        "  text = text.lower()\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [word for word in tokens if word not in stop_words]  # убираем стоп-слова\n",
        "  tokens = word_tokenize(re.sub(r'[^a-zA-Zа-яА-Я ]', '', ' '.join(tokens)))  # убираем спец символы, числа и знаки препинания\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp73e19L-Hkm"
      },
      "outputs": [],
      "source": [
        "print(stopwords_special(news_example))\n",
        "print(stopwords_special(imdb_example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sth4jjHB-YNx"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "def nouns_adj(text):\n",
        "  tokens = stopwords_special(text)\n",
        "  tagged_token = pos_tag(tokens)\n",
        "  res = [word for word, label in tagged_token if label.startswith('N') or label.startswith('J')]  # береём только ИС и ИП\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvPOOMwJ-kH4"
      },
      "outputs": [],
      "source": [
        "print(nouns_adj(news_example))\n",
        "print(nouns_adj(imdb_example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5pHZQBz-03s"
      },
      "outputs": [],
      "source": [
        "# стемминг с удалением стоп-слов, спец.символов, знаков препинания + оставляем ИС и ИП\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "def stemming(text):\n",
        "  tokens = nouns_adj(text)\n",
        "\n",
        "  stemmer = nltk.PorterStemmer()  # инициализируем стеммер\n",
        "  stemmed_tokens = [stemmer.stem(token) for token in tokens]  # перебираем токены и применяем алгоритм стемминга\n",
        "\n",
        "  return stemmed_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwnofl0M_STy"
      },
      "outputs": [],
      "source": [
        "print(stemming(news_example))\n",
        "print(stemming(imdb_example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSfKl1fE_XfW"
      },
      "outputs": [],
      "source": [
        "def lemma(text):\n",
        "  tokens = nouns_adj(text)\n",
        "  lemmatizer = nltk.WordNetLemmatizer()\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "  return lemmatized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdfIdmb0_r_D"
      },
      "outputs": [],
      "source": [
        "print(lemma(news_example))\n",
        "print(lemma(imdb_example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo94aemOCBfm"
      },
      "source": [
        "# 3. Универсальная функция векторизации (через CountVectorizer, TfidfVectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAv3RzaPCOSE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# method - \"count\"/\"tfdf\"\n",
        "# edit - 1 (stopwords_special), 2 (nouns_adj), 3 (стемминг), 4 (лемматизация)\n",
        "\n",
        "def vectorize(train_texts, test_texts, method, edit):\n",
        "  if method == \"count\":\n",
        "    vectorizer = CountVectorizer()\n",
        "  else:\n",
        "    vectorizer = TfidfVectorizer()\n",
        "\n",
        "  if edit == 1:\n",
        "    train_texts = [' '.join(stopwords_special(text)) for text in train_texts]\n",
        "    test_texts = [' '.join(stopwords_special(text)) for text in test_texts]\n",
        "  elif edit == 2:\n",
        "    train_texts = [' '.join(nouns_adj(text)) for text in train_texts]\n",
        "    test_texts = [' '.join(nouns_adj(text)) for text in test_texts]\n",
        "  elif edit == 3:\n",
        "    train_texts = [' '.join(stemming(text)) for text in train_texts]\n",
        "    test_texts = [' '.join(stemming(text)) for text in test_texts]\n",
        "  else:\n",
        "    train_texts = [' '.join(lemma(text)) for text in train_texts]\n",
        "    test_texts = [' '.join(lemma(text)) for text in test_texts]\n",
        "\n",
        "  train_text = vectorizer.fit_transform(train_texts)\n",
        "  test_text = vectorizer.transform(test_texts)\n",
        "\n",
        "  return train_text, test_text, vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm_VHSHaD25q"
      },
      "outputs": [],
      "source": [
        "for index in ['n', 'i']:\n",
        "  for m in ['count', 'tfidf']:\n",
        "    for edit in range(1, 5):\n",
        "      res = 'Dataset: '\n",
        "      if index == 'n':\n",
        "        res += 'news, Vectorizer: '\n",
        "        train, test = train_texts_news, test_texts_news\n",
        "      else:\n",
        "        res += 'imdb, Vectorizer: '\n",
        "        train, test = train_texts_imdb, test_texts_imdb\n",
        "\n",
        "      if m == 'count':\n",
        "        res += 'count, Edit method: '\n",
        "      else:\n",
        "        res += 'tfidf, Edit method: '\n",
        "\n",
        "      if edit == 1:\n",
        "        res += 'stopwords_special'\n",
        "      elif edit == 2:\n",
        "        res += 'nouns_adj'\n",
        "      elif edit == 3:\n",
        "        res += 'stemming'\n",
        "      else:\n",
        "        res += 'lemma'\n",
        "\n",
        "      train_text, test_text = vectorize(train, test, m, edit)[0:2]\n",
        "      print(res)\n",
        "      print('Объем train: ', len(train_text.toarray()), 'Объём test: ', len(test_text.toarray()))\n",
        "      print('Размерность Train: ', len(train_text.toarray()[0]), 'Размерность Test: ', len(test_text.toarray()[0]))\n",
        "      print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZeRlIIMM9Ow",
        "outputId": "81e91cbe-7088-4d7a-af7f-77e925d8bb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: news, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.758     0.746     0.752       390\n",
            "           1      0.779     0.871     0.823       410\n",
            "           2      0.721     0.698     0.709       388\n",
            "           3      0.715     0.663     0.688       412\n",
            "\n",
            "    accuracy                          0.745      1600\n",
            "   macro avg      0.743     0.744     0.743      1600\n",
            "weighted avg      0.743     0.745     0.743      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.754     0.700     0.726       390\n",
            "           1      0.757     0.866     0.808       410\n",
            "           2      0.736     0.698     0.717       388\n",
            "           3      0.733     0.714     0.723       412\n",
            "\n",
            "    accuracy                          0.746      1600\n",
            "   macro avg      0.745     0.744     0.743      1600\n",
            "weighted avg      0.745     0.746     0.744      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.739     0.754     0.746       390\n",
            "           1      0.817     0.859     0.837       410\n",
            "           2      0.735     0.701     0.718       388\n",
            "           3      0.708     0.689     0.699       412\n",
            "\n",
            "    accuracy                          0.751      1600\n",
            "   macro avg      0.750     0.751     0.750      1600\n",
            "weighted avg      0.750     0.751     0.750      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.718     0.782     0.748       390\n",
            "           1      0.812     0.873     0.841       410\n",
            "           2      0.723     0.701     0.712       388\n",
            "           3      0.765     0.665     0.712       412\n",
            "\n",
            "    accuracy                          0.756      1600\n",
            "   macro avg      0.755     0.755     0.753      1600\n",
            "weighted avg      0.755     0.756     0.754      1600\n",
            "\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.708     0.672     0.689       390\n",
            "           1      0.764     0.868     0.813       410\n",
            "           2      0.711     0.665     0.687       388\n",
            "           3      0.696     0.677     0.686       412\n",
            "\n",
            "    accuracy                          0.722      1600\n",
            "   macro avg      0.720     0.721     0.719      1600\n",
            "weighted avg      0.720     0.722     0.720      1600\n",
            "\n",
            "       00  000  000m  001   01  010   02   03  033   04  ...  zones  zoo  \\\n",
            "0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "1     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "2     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "3     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "4     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "...   ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...    ...  ...   \n",
            "6395  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6396  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6397  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6398  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6399  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "\n",
            "      zook  zooms  zurab  zurich  zvezda  zviadauri  zvidauri  zvonareva  \n",
            "0      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "1      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "2      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "3      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "4      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "...    ...    ...    ...     ...     ...        ...       ...        ...  \n",
            "6395   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6396   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6397   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6398   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6399   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "\n",
            "[6400 rows x 18126 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.689     0.710     0.699       390\n",
            "           1      0.765     0.859     0.809       410\n",
            "           2      0.703     0.652     0.676       388\n",
            "           3      0.712     0.653     0.681       412\n",
            "\n",
            "    accuracy                          0.719      1600\n",
            "   macro avg      0.717     0.718     0.717      1600\n",
            "weighted avg      0.718     0.719     0.717      1600\n",
            "\n",
            "       00  000  000m  001   01  010   02   03  033   04  ...  zones  zoo  \\\n",
            "0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "1     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "2     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "3     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "4     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "...   ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...    ...  ...   \n",
            "6395  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6396  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6397  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6398  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6399  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "\n",
            "      zook  zooms  zurab  zurich  zvezda  zviadauri  zvidauri  zvonareva  \n",
            "0      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "1      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "2      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "3      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "4      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "...    ...    ...    ...     ...     ...        ...       ...        ...  \n",
            "6395   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6396   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6397   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6398   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6399   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "\n",
            "[6400 rows x 18126 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.692     0.715     0.704       390\n",
            "           1      0.783     0.844     0.812       410\n",
            "           2      0.714     0.670     0.691       388\n",
            "           3      0.719     0.682     0.700       412\n",
            "\n",
            "    accuracy                          0.729      1600\n",
            "   macro avg      0.727     0.728     0.727      1600\n",
            "weighted avg      0.728     0.729     0.728      1600\n",
            "\n",
            "       00  000  000m  001   01  010   02   03  033   04  ...  zones  zoo  \\\n",
            "0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "1     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "2     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "3     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "4     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "...   ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...    ...  ...   \n",
            "6395  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6396  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6397  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6398  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6399  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "\n",
            "      zook  zooms  zurab  zurich  zvezda  zviadauri  zvidauri  zvonareva  \n",
            "0      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "1      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "2      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "3      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "4      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "...    ...    ...    ...     ...     ...        ...       ...        ...  \n",
            "6395   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6396   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6397   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6398   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6399   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "\n",
            "[6400 rows x 18126 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.699     0.726     0.712       390\n",
            "           1      0.781     0.861     0.819       410\n",
            "           2      0.712     0.670     0.691       388\n",
            "           3      0.735     0.675     0.704       412\n",
            "\n",
            "    accuracy                          0.734      1600\n",
            "   macro avg      0.732     0.733     0.731      1600\n",
            "weighted avg      0.733     0.734     0.732      1600\n",
            "\n",
            "       00  000  000m  001   01  010   02   03  033   04  ...  zones  zoo  \\\n",
            "0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "1     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "2     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "3     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "4     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "...   ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...    ...  ...   \n",
            "6395  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6396  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6397  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6398  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "6399  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0   \n",
            "\n",
            "      zook  zooms  zurab  zurich  zvezda  zviadauri  zvidauri  zvonareva  \n",
            "0      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "1      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "2      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "3      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "4      0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "...    ...    ...    ...     ...     ...        ...       ...        ...  \n",
            "6395   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6396   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6397   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6398   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "6399   0.0    0.0    0.0     0.0     0.0        0.0       0.0        0.0  \n",
            "\n",
            "[6400 rows x 18126 columns]\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.710     0.720     0.715       794\n",
            "           1      0.720     0.710     0.715       806\n",
            "\n",
            "    accuracy                          0.715      1600\n",
            "   macro avg      0.715     0.715     0.715      1600\n",
            "weighted avg      0.715     0.715     0.715      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.689     0.718     0.703       794\n",
            "           1      0.710     0.681     0.695       806\n",
            "\n",
            "    accuracy                          0.699      1600\n",
            "   macro avg      0.700     0.700     0.699      1600\n",
            "weighted avg      0.700     0.699     0.699      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.686     0.703     0.694       794\n",
            "           1      0.700     0.682     0.691       806\n",
            "\n",
            "    accuracy                          0.693      1600\n",
            "   macro avg      0.693     0.693     0.692      1600\n",
            "weighted avg      0.693     0.693     0.692      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.703     0.713     0.708       794\n",
            "           1      0.713     0.703     0.708       806\n",
            "\n",
            "    accuracy                          0.708      1600\n",
            "   macro avg      0.708     0.708     0.708      1600\n",
            "weighted avg      0.708     0.708     0.708      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.687     0.695     0.691       794\n",
            "           1      0.696     0.689     0.692       806\n",
            "\n",
            "    accuracy                          0.692      1600\n",
            "   macro avg      0.692     0.692     0.692      1600\n",
            "weighted avg      0.692     0.692     0.692      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.675     0.693     0.684       794\n",
            "           1      0.689     0.671     0.680       806\n",
            "\n",
            "    accuracy                          0.682      1600\n",
            "   macro avg      0.682     0.682     0.682      1600\n",
            "weighted avg      0.682     0.682     0.682      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.677     0.695     0.686       794\n",
            "           1      0.692     0.674     0.683       806\n",
            "\n",
            "    accuracy                          0.684      1600\n",
            "   macro avg      0.685     0.684     0.684      1600\n",
            "weighted avg      0.685     0.684     0.684      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.688     0.693     0.691       794\n",
            "           1      0.695     0.691     0.693       806\n",
            "\n",
            "    accuracy                          0.692      1600\n",
            "   macro avg      0.692     0.692     0.692      1600\n",
            "weighted avg      0.692     0.692     0.692      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n"
          ]
        }
      ],
      "source": [
        "# импортируем DecisionTree и метрики\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# на каждом из предыдущих вариантов обучаем - выводим таблицу метрик и там, где vectorizer - матрицу признаков tf-idf\n",
        "for index in ['n', 'i']:\n",
        "  for m in ['count', 'tfidf']:\n",
        "    for edit in range(1, 5):\n",
        "      res = 'Dataset: '\n",
        "      if index == 'n':\n",
        "        res += 'news, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_news, test_texts_news, train_labels_news, test_labels_news\n",
        "      else:\n",
        "        res += 'imdb, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_imdb, test_texts_imdb, train_labels_imdb, test_labels_imdb\n",
        "\n",
        "      if m == 'count':\n",
        "        res += 'count, Edit method: '\n",
        "      else:\n",
        "        res += 'tfidf, Edit method: '\n",
        "\n",
        "      if edit == 1:\n",
        "        res += 'stopwords_special'\n",
        "      elif edit == 2:\n",
        "        res += 'nouns_adj'\n",
        "      elif edit == 3:\n",
        "        res += 'stemming'\n",
        "      else:\n",
        "        res += 'lemma'\n",
        "\n",
        "      vect = vectorize(train_text, test_text, m, edit)\n",
        "      train_text, test_text = vect[0:2]\n",
        "\n",
        "      # Обучение модели на тренировочных данных\n",
        "      dtc = DecisionTreeClassifier(random_state=42)\n",
        "      dtc.fit(train_text, train_label)\n",
        "\n",
        "      # Предсказание на тестовых данных\n",
        "      y_pred = dtc.predict(test_text)\n",
        "      # Выводим F1-score по разным методам усреднения\n",
        "      report = classification_report(test_label, y_pred, digits=3)\n",
        "      print(res)\n",
        "      print(report)\n",
        "\n",
        "      if m == 'tfidf':\n",
        "        if index == 'n':\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_news).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)\n",
        "        else:\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_imdb).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqR5YbV9m1gO",
        "outputId": "9b9ab06f-0c40-4ab6-b4d8-8a5da6bd9eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: news, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.894     0.803     0.846       390\n",
            "           1      0.858     0.956     0.904       410\n",
            "           2      0.822     0.786     0.804       388\n",
            "           3      0.775     0.794     0.784       412\n",
            "\n",
            "    accuracy                          0.836      1600\n",
            "   macro avg      0.837     0.835     0.835      1600\n",
            "weighted avg      0.837     0.836     0.835      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.880     0.790     0.832       390\n",
            "           1      0.844     0.949     0.893       410\n",
            "           2      0.827     0.776     0.801       388\n",
            "           3      0.774     0.799     0.786       412\n",
            "\n",
            "    accuracy                          0.829      1600\n",
            "   macro avg      0.831     0.828     0.828      1600\n",
            "weighted avg      0.831     0.829     0.828      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.872     0.805     0.837       390\n",
            "           1      0.856     0.954     0.902       410\n",
            "           2      0.821     0.768     0.794       388\n",
            "           3      0.788     0.803     0.796       412\n",
            "\n",
            "    accuracy                          0.834      1600\n",
            "   macro avg      0.834     0.833     0.832      1600\n",
            "weighted avg      0.834     0.834     0.833      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.874     0.800     0.835       390\n",
            "           1      0.863     0.956     0.907       410\n",
            "           2      0.812     0.781     0.796       388\n",
            "           3      0.791     0.799     0.795       412\n",
            "\n",
            "    accuracy                          0.835      1600\n",
            "   macro avg      0.835     0.834     0.833      1600\n",
            "weighted avg      0.835     0.835     0.834      1600\n",
            "\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.881     0.815     0.847       390\n",
            "           1      0.854     0.959     0.903       410\n",
            "           2      0.831     0.776     0.803       388\n",
            "           3      0.777     0.786     0.782       412\n",
            "\n",
            "    accuracy                          0.835      1600\n",
            "   macro avg      0.836     0.834     0.834      1600\n",
            "weighted avg      0.835     0.835     0.834      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.870     0.792     0.830       390\n",
            "           1      0.846     0.941     0.891       410\n",
            "           2      0.818     0.763     0.789       388\n",
            "           3      0.782     0.811     0.796       412\n",
            "\n",
            "    accuracy                          0.828      1600\n",
            "   macro avg      0.829     0.827     0.827      1600\n",
            "weighted avg      0.829     0.828     0.827      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.866     0.797     0.830       390\n",
            "           1      0.853     0.961     0.904       410\n",
            "           2      0.828     0.781     0.804       388\n",
            "           3      0.794     0.796     0.795       412\n",
            "\n",
            "    accuracy                          0.835      1600\n",
            "   macro avg      0.835     0.834     0.833      1600\n",
            "weighted avg      0.835     0.835     0.834      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.869     0.800     0.833       390\n",
            "           1      0.854     0.956     0.902       410\n",
            "           2      0.819     0.771     0.794       388\n",
            "           3      0.796     0.806     0.801       412\n",
            "\n",
            "    accuracy                          0.834      1600\n",
            "   macro avg      0.835     0.833     0.833      1600\n",
            "weighted avg      0.834     0.834     0.833      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.860     0.845     0.853       794\n",
            "           1      0.850     0.865     0.857       806\n",
            "\n",
            "    accuracy                          0.855      1600\n",
            "   macro avg      0.855     0.855     0.855      1600\n",
            "weighted avg      0.855     0.855     0.855      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.851     0.832     0.842       794\n",
            "           1      0.838     0.856     0.847       806\n",
            "\n",
            "    accuracy                          0.844      1600\n",
            "   macro avg      0.845     0.844     0.844      1600\n",
            "weighted avg      0.845     0.844     0.844      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.841     0.829     0.835       794\n",
            "           1      0.834     0.846     0.840       806\n",
            "\n",
            "    accuracy                          0.838      1600\n",
            "   macro avg      0.838     0.837     0.837      1600\n",
            "weighted avg      0.838     0.838     0.837      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.842     0.816     0.829       794\n",
            "           1      0.824     0.849     0.836       806\n",
            "\n",
            "    accuracy                          0.833      1600\n",
            "   macro avg      0.833     0.832     0.832      1600\n",
            "weighted avg      0.833     0.833     0.832      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.847     0.844     0.845       794\n",
            "           1      0.847     0.850     0.848       806\n",
            "\n",
            "    accuracy                          0.847      1600\n",
            "   macro avg      0.847     0.847     0.847      1600\n",
            "weighted avg      0.847     0.847     0.847      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.833     0.825     0.829       794\n",
            "           1      0.829     0.837     0.833       806\n",
            "\n",
            "    accuracy                          0.831      1600\n",
            "   macro avg      0.831     0.831     0.831      1600\n",
            "weighted avg      0.831     0.831     0.831      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.842     0.824     0.833       794\n",
            "           1      0.830     0.847     0.839       806\n",
            "\n",
            "    accuracy                          0.836      1600\n",
            "   macro avg      0.836     0.836     0.836      1600\n",
            "weighted avg      0.836     0.836     0.836      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.832     0.831     0.832       794\n",
            "           1      0.834     0.835     0.834       806\n",
            "\n",
            "    accuracy                          0.833      1600\n",
            "   macro avg      0.833     0.833     0.833      1600\n",
            "weighted avg      0.833     0.833     0.833      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n"
          ]
        }
      ],
      "source": [
        "# обучаем random_forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# на каждом из предыдущих вариантов обучаем - выводим таблицу метрик и там, где vectorizer - матрицу признаков tf-idf\n",
        "for index in ['n', 'i']:\n",
        "  for m in ['count', 'tfidf']:\n",
        "    for edit in range(1, 5):\n",
        "      res = 'Dataset: '\n",
        "      if index == 'n':\n",
        "        res += 'news, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_news, test_texts_news, train_labels_news, test_labels_news\n",
        "        rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "      else:\n",
        "        res += 'imdb, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_imdb, test_texts_imdb, train_labels_imdb, test_labels_imdb\n",
        "        rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
        "\n",
        "      if m == 'count':\n",
        "        res += 'count, Edit method: '\n",
        "      else:\n",
        "        res += 'tfidf, Edit method: '\n",
        "\n",
        "      if edit == 1:\n",
        "        res += 'stopwords_special'\n",
        "      elif edit == 2:\n",
        "        res += 'nouns_adj'\n",
        "      elif edit == 3:\n",
        "        res += 'stemming'\n",
        "      else:\n",
        "        res += 'lemma'\n",
        "\n",
        "      vect = vectorize(train_text, test_text, m, edit)\n",
        "      train_text, test_text = vect[0:2]\n",
        "\n",
        "      # Обучение модели на тренировочных данных\n",
        "      rf.fit(train_text, train_label)\n",
        "\n",
        "      # Предсказание на тестовых данных\n",
        "      y_pred = rf.predict(test_text)\n",
        "      # Выводим F1-score по разным методам усреднения\n",
        "      report = classification_report(test_label, y_pred, digits=3)\n",
        "      print(res)\n",
        "      print(report)\n",
        "\n",
        "      if m == 'tfidf':\n",
        "        if index == 's':\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_news).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)\n",
        "        else:\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_imdb).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhUh1XYAYOGA",
        "outputId": "4957bebc-a7da-411d-c7e8-ff626dea7cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: news, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.864     0.813     0.838       390\n",
            "           1      0.907     0.949     0.927       410\n",
            "           2      0.807     0.817     0.812       388\n",
            "           3      0.803     0.801     0.802       412\n",
            "\n",
            "    accuracy                          0.846      1600\n",
            "   macro avg      0.845     0.845     0.845      1600\n",
            "weighted avg      0.845     0.846     0.845      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.846     0.803     0.824       390\n",
            "           1      0.893     0.937     0.914       410\n",
            "           2      0.829     0.789     0.808       388\n",
            "           3      0.782     0.818     0.800       412\n",
            "\n",
            "    accuracy                          0.838      1600\n",
            "   macro avg      0.838     0.836     0.836      1600\n",
            "weighted avg      0.837     0.838     0.837      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.855     0.803     0.828       390\n",
            "           1      0.894     0.941     0.917       410\n",
            "           2      0.830     0.804     0.817       388\n",
            "           3      0.803     0.830     0.816       412\n",
            "\n",
            "    accuracy                          0.846      1600\n",
            "   macro avg      0.845     0.845     0.844      1600\n",
            "weighted avg      0.845     0.846     0.845      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.849     0.805     0.826       390\n",
            "           1      0.897     0.934     0.915       410\n",
            "           2      0.820     0.799     0.809       388\n",
            "           3      0.798     0.823     0.810       412\n",
            "\n",
            "    accuracy                          0.841      1600\n",
            "   macro avg      0.841     0.840     0.840      1600\n",
            "weighted avg      0.841     0.841     0.841      1600\n",
            "\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.847     0.810     0.828       390\n",
            "           1      0.887     0.939     0.912       410\n",
            "           2      0.810     0.802     0.806       388\n",
            "           3      0.804     0.799     0.801       412\n",
            "\n",
            "    accuracy                          0.838      1600\n",
            "   macro avg      0.837     0.837     0.837      1600\n",
            "weighted avg      0.837     0.838     0.837      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.832     0.815     0.824       390\n",
            "           1      0.902     0.920     0.911       410\n",
            "           2      0.821     0.768     0.794       388\n",
            "           3      0.773     0.820     0.796       412\n",
            "\n",
            "    accuracy                          0.832      1600\n",
            "   macro avg      0.832     0.831     0.831      1600\n",
            "weighted avg      0.832     0.832     0.832      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.834     0.810     0.822       390\n",
            "           1      0.901     0.932     0.916       410\n",
            "           2      0.825     0.778     0.801       388\n",
            "           3      0.794     0.830     0.811       412\n",
            "\n",
            "    accuracy                          0.839      1600\n",
            "   macro avg      0.838     0.838     0.838      1600\n",
            "weighted avg      0.839     0.839     0.838      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.849     0.823     0.836       390\n",
            "           1      0.903     0.934     0.918       410\n",
            "           2      0.821     0.781     0.801       388\n",
            "           3      0.788     0.820     0.804       412\n",
            "\n",
            "    accuracy                          0.841      1600\n",
            "   macro avg      0.840     0.840     0.840      1600\n",
            "weighted avg      0.840     0.841     0.840      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.855     0.802     0.828       794\n",
            "           1      0.816     0.866     0.840       806\n",
            "\n",
            "    accuracy                          0.834      1600\n",
            "   macro avg      0.836     0.834     0.834      1600\n",
            "weighted avg      0.836     0.834     0.834      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.833     0.787     0.810       794\n",
            "           1      0.801     0.845     0.822       806\n",
            "\n",
            "    accuracy                          0.816      1600\n",
            "   macro avg      0.817     0.816     0.816      1600\n",
            "weighted avg      0.817     0.816     0.816      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.841     0.788     0.814       794\n",
            "           1      0.804     0.854     0.828       806\n",
            "\n",
            "    accuracy                          0.821      1600\n",
            "   macro avg      0.823     0.821     0.821      1600\n",
            "weighted avg      0.822     0.821     0.821      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.835     0.785     0.809       794\n",
            "           1      0.800     0.847     0.823       806\n",
            "\n",
            "    accuracy                          0.816      1600\n",
            "   macro avg      0.817     0.816     0.816      1600\n",
            "weighted avg      0.817     0.816     0.816      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.855     0.792     0.822       794\n",
            "           1      0.809     0.867     0.837       806\n",
            "\n",
            "    accuracy                          0.830      1600\n",
            "   macro avg      0.832     0.830     0.830      1600\n",
            "weighted avg      0.832     0.830     0.830      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.836     0.787     0.811       794\n",
            "           1      0.802     0.847     0.824       806\n",
            "\n",
            "    accuracy                          0.818      1600\n",
            "   macro avg      0.819     0.817     0.817      1600\n",
            "weighted avg      0.818     0.818     0.817      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.838     0.782     0.809       794\n",
            "           1      0.799     0.851     0.824       806\n",
            "\n",
            "    accuracy                          0.817      1600\n",
            "   macro avg      0.818     0.817     0.817      1600\n",
            "weighted avg      0.818     0.817     0.817      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.831     0.780     0.804       794\n",
            "           1      0.795     0.844     0.819       806\n",
            "\n",
            "    accuracy                          0.812      1600\n",
            "   macro avg      0.813     0.812     0.812      1600\n",
            "weighted avg      0.813     0.812     0.812      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n"
          ]
        }
      ],
      "source": [
        "# теперь обучаем на GBM\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# на каждом из предыдущих вариантов обучаем - выводим таблицу метрик и там, где vectorizer - матрицу признаков tf-idf\n",
        "for index in ['n', 'i']:\n",
        "  for m in ['count', 'tfidf']:\n",
        "    for edit in range(1, 5):\n",
        "      res = 'Dataset: '\n",
        "      if index == 'n':\n",
        "        res += 'news, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_news, test_texts_news, train_labels_news, test_labels_news\n",
        "        gbm = GradientBoostingClassifier(\n",
        "            n_estimators=300,        # Количество деревьев\n",
        "            learning_rate=0.05,      # Скорость обучения\n",
        "            max_depth=4,             # Глубина деревьев\n",
        "            min_samples_split=10,    # Минимальное количество объектов для разбиения\n",
        "            min_samples_leaf=5,      # Минимальный размер листа\n",
        "            random_state=42)\n",
        "      else:\n",
        "        res += 'imdb, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_imdb, test_texts_imdb, train_labels_imdb, test_labels_imdb\n",
        "        gbm = GradientBoostingClassifier(\n",
        "            n_estimators=300,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=4,\n",
        "            min_samples_split=10,\n",
        "            min_samples_leaf=5,\n",
        "            random_state=42)\n",
        "\n",
        "      if m == 'count':\n",
        "        res += 'count, Edit method: '\n",
        "      else:\n",
        "        res += 'tfidf, Edit method: '\n",
        "\n",
        "      if edit == 1:\n",
        "        res += 'stopwords_special'\n",
        "      elif edit == 2:\n",
        "        res += 'nouns_adj'\n",
        "      elif edit == 3:\n",
        "        res += 'stemming'\n",
        "      else:\n",
        "        res += 'lemma'\n",
        "\n",
        "      vect = vectorize(train_text, test_text, m, edit)\n",
        "      train_text, test_text = vect[0:2]\n",
        "\n",
        "      # Обучение модели на тренировочных данных\n",
        "      gbm.fit(train_text, train_label)\n",
        "\n",
        "      # Предсказание на тестовых данных\n",
        "      y_pred = gbm.predict(test_text)\n",
        "      # Выводим F1-score по разным методам усреднения\n",
        "      report = classification_report(test_label, y_pred, digits=3)\n",
        "      print(res)\n",
        "      print(report)\n",
        "\n",
        "      if m == 'tfidf':\n",
        "        if index == 's':\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_news).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)\n",
        "        else:\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_imdb).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExYU_9ltdkR6",
        "outputId": "01951228-4012-4073-8f83-825818fa32d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: news, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.655     0.467     0.545       390\n",
            "           1      0.858     0.573     0.687       410\n",
            "           2      0.672     0.448     0.538       388\n",
            "           3      0.399     0.765     0.525       412\n",
            "\n",
            "    accuracy                          0.566      1600\n",
            "   macro avg      0.646     0.563     0.574      1600\n",
            "weighted avg      0.645     0.566     0.574      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.639     0.485     0.551       390\n",
            "           1      0.847     0.539     0.659       410\n",
            "           2      0.707     0.405     0.515       388\n",
            "           3      0.404     0.806     0.539       412\n",
            "\n",
            "    accuracy                          0.562      1600\n",
            "   macro avg      0.649     0.559     0.566      1600\n",
            "weighted avg      0.648     0.562     0.567      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.533     0.503     0.517       390\n",
            "           1      0.839     0.510     0.634       410\n",
            "           2      0.711     0.487     0.578       388\n",
            "           3      0.448     0.779     0.569       412\n",
            "\n",
            "    accuracy                          0.572      1600\n",
            "   macro avg      0.633     0.570     0.575      1600\n",
            "weighted avg      0.632     0.572     0.575      1600\n",
            "\n",
            "Dataset: news, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.362     0.882     0.513       390\n",
            "           1      0.849     0.549     0.667       410\n",
            "           2      0.712     0.477     0.571       388\n",
            "           3      0.784     0.238     0.365       412\n",
            "\n",
            "    accuracy                          0.532      1600\n",
            "   macro avg      0.677     0.536     0.529      1600\n",
            "weighted avg      0.680     0.532     0.528      1600\n",
            "\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.651     0.454     0.535       390\n",
            "           1      0.857     0.583     0.694       410\n",
            "           2      0.681     0.451     0.543       388\n",
            "           3      0.400     0.769     0.527       412\n",
            "\n",
            "    accuracy                          0.568      1600\n",
            "   macro avg      0.647     0.564     0.574      1600\n",
            "weighted avg      0.646     0.568     0.575      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.643     0.485     0.553       390\n",
            "           1      0.855     0.532     0.656       410\n",
            "           2      0.720     0.418     0.529       388\n",
            "           3      0.404     0.811     0.540       412\n",
            "\n",
            "    accuracy                          0.564      1600\n",
            "   macro avg      0.656     0.561     0.569      1600\n",
            "weighted avg      0.654     0.564     0.570      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.577     0.492     0.531       390\n",
            "           1      0.860     0.507     0.638       410\n",
            "           2      0.721     0.479     0.576       388\n",
            "           3      0.430     0.801     0.560       412\n",
            "\n",
            "    accuracy                          0.573      1600\n",
            "   macro avg      0.647     0.570     0.576      1600\n",
            "weighted avg      0.646     0.573     0.577      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: news, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.375     0.882     0.526       390\n",
            "           1      0.847     0.580     0.689       410\n",
            "           2      0.736     0.482     0.583       388\n",
            "           3      0.796     0.284     0.419       412\n",
            "\n",
            "    accuracy                          0.554      1600\n",
            "   macro avg      0.688     0.557     0.554      1600\n",
            "weighted avg      0.692     0.554     0.554      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.830     0.622     0.711       794\n",
            "           1      0.701     0.875     0.779       806\n",
            "\n",
            "    accuracy                          0.749      1600\n",
            "   macro avg      0.766     0.748     0.745      1600\n",
            "weighted avg      0.765     0.749     0.745      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.814     0.596     0.688       794\n",
            "           1      0.685     0.866     0.765       806\n",
            "\n",
            "    accuracy                          0.732      1600\n",
            "   macro avg      0.750     0.731     0.726      1600\n",
            "weighted avg      0.749     0.732     0.727      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.821     0.601     0.694       794\n",
            "           1      0.689     0.871     0.769       806\n",
            "\n",
            "    accuracy                          0.737      1600\n",
            "   macro avg      0.755     0.736     0.732      1600\n",
            "weighted avg      0.754     0.737     0.732      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: count, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.810     0.630     0.709       794\n",
            "           1      0.701     0.855     0.770       806\n",
            "\n",
            "    accuracy                          0.743      1600\n",
            "   macro avg      0.756     0.742     0.739      1600\n",
            "weighted avg      0.755     0.743     0.740      1600\n",
            "\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stopwords_special\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.823     0.586     0.684       794\n",
            "           1      0.682     0.876     0.767       806\n",
            "\n",
            "    accuracy                          0.732      1600\n",
            "   macro avg      0.753     0.731     0.726      1600\n",
            "weighted avg      0.752     0.732     0.726      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: nouns_adj\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.828     0.565     0.672       794\n",
            "           1      0.674     0.885     0.765       806\n",
            "\n",
            "    accuracy                          0.726      1600\n",
            "   macro avg      0.751     0.725     0.719      1600\n",
            "weighted avg      0.751     0.726     0.719      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: stemming\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.828     0.550     0.661       794\n",
            "           1      0.667     0.887     0.761       806\n",
            "\n",
            "    accuracy                          0.720      1600\n",
            "   macro avg      0.747     0.719     0.711      1600\n",
            "weighted avg      0.747     0.720     0.712      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n",
            "Dataset: imdb, Vectorizer: tfidf, Edit method: lemma\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.823     0.555     0.663       794\n",
            "           1      0.668     0.882     0.760       806\n",
            "\n",
            "    accuracy                          0.720      1600\n",
            "   macro avg      0.745     0.719     0.712      1600\n",
            "weighted avg      0.745     0.720     0.712      1600\n",
            "\n",
            "       00  000  00001  007  0079  0080  0083  00am  00pm  00s  ...  zzzzzzzz  \\\n",
            "0     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "1     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "2     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "3     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "4     0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "...   ...  ...    ...  ...   ...   ...   ...   ...   ...  ...  ...       ...   \n",
            "6395  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6396  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6397  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6398  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "6399  0.0  0.0    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  ...       0.0   \n",
            "\n",
            "      zzzzzzzzzzzzz   zé  álex  âme   är  äänekoski  élan  émigrés  étc  \n",
            "0               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "1               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "2               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "3               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "4               0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "...             ...  ...   ...  ...  ...        ...   ...      ...  ...  \n",
            "6395            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6396            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6397            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6398            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "6399            0.0  0.0   0.0  0.0  0.0        0.0   0.0      0.0  0.0  \n",
            "\n",
            "[6400 rows x 41119 columns]\n"
          ]
        }
      ],
      "source": [
        "# обучаем AdaBoost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# на каждом из предыдущих вариантов обучаем - выводим таблицу метрик и там, где vectorizer - матрицу признаков tf-idf\n",
        "for index in ['n', 'i']:\n",
        "  for m in ['count', 'tfidf']:\n",
        "    for edit in range(1, 5):\n",
        "      res = 'Dataset: '\n",
        "      if index == 'n':\n",
        "        res += 'news, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_news, test_texts_news, train_labels_news, test_labels_news\n",
        "        adaboost = AdaBoostClassifier(\n",
        "          estimator=DecisionTreeClassifier(max_depth=2),  # Базовое дерево\n",
        "          n_estimators=200,      # Больше деревьев для точности\n",
        "          learning_rate=0.1,     # Оптимальный баланс между скоростью и качеством\n",
        "          random_state=42)\n",
        "      else:\n",
        "        res += 'imdb, Vectorizer: '\n",
        "        train_text, test_text, train_label, test_label = train_texts_imdb, test_texts_imdb, train_labels_imdb, test_labels_imdb\n",
        "        adaboost = AdaBoostClassifier(\n",
        "          estimator=DecisionTreeClassifier(max_depth=2),  # Базовое дерево\n",
        "          n_estimators=200,      # Больше деревьев для точности\n",
        "          learning_rate=0.1,     # Оптимальный баланс между скоростью и качеством\n",
        "          random_state=42)\n",
        "\n",
        "      if m == 'count':\n",
        "        res += 'count, Edit method: '\n",
        "      else:\n",
        "        res += 'tfidf, Edit method: '\n",
        "\n",
        "      if edit == 1:\n",
        "        res += 'stopwords_special'\n",
        "      elif edit == 2:\n",
        "        res += 'nouns_adj'\n",
        "      elif edit == 3:\n",
        "        res += 'stemming'\n",
        "      else:\n",
        "        res += 'lemma'\n",
        "\n",
        "      vect = vectorize(train_text, test_text, m, edit)\n",
        "      train_text, test_text = vect[0:2]\n",
        "\n",
        "      # Обучение модели на тренировочных данных\n",
        "      adaboost.fit(train_text, train_label)\n",
        "\n",
        "      # Предсказание на тестовых данных\n",
        "      y_pred = adaboost.predict(test_text)\n",
        "      # Выводим F1-score по разным методам усреднения\n",
        "      report = classification_report(test_label, y_pred, digits=3)\n",
        "      print(res)\n",
        "      print(report)\n",
        "\n",
        "      if m == 'tfidf':\n",
        "        if index == 's':\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_news).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)\n",
        "        else:\n",
        "          # Преобразуем матрицу в DataFrame для удобства\n",
        "          df = pd.DataFrame(vect[2].fit_transform(train_texts_imdb).toarray(), columns=vect[2].get_feature_names_out())\n",
        "          print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
